{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3fa934",
   "metadata": {},
   "source": [
    "## This jupyter notebook is to test the model we have created in the ```modelTraining.ipynb``` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b6d9b",
   "metadata": {},
   "source": [
    "###### The below cell of codes is to import various modules in order to run our test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86729f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model # load_model is to call the trained model, that is model.h5 that we have created.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "793ab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"./model.h5\" # Giving the path of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83467104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(modelPath) # Loading the model by the help of load_model from the path we have specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8914b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = r\"./\" # Defining the output path for the predicted file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24b6276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = r\"./IMG_20191117_171753.jpg\" # Defining the path for the image to be given as input while test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a894c",
   "metadata": {},
   "source": [
    "###### In the below line of code we have used a function of cv2, that is cascade classifier. It is used for object detection in images by help of various algorithms. Algorithm we used here is : \n",
    "* ```haarcascade_frontalface_default.xml```, by this algorithm, we can detect the face of each indivizuals we input as image to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "692a7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa889ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = cv2.imread(imagePath) # Reading the image file from the path provided and saving it in the \"pic\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9e025",
   "metadata": {},
   "source": [
    "###### In the below cell of code we change the color of the image from default BGR to GRAY, and we do it mainly because : \n",
    "* Grayscale simplifies the algorithm and reduces computational requirements. Indeed, color may be of limited benefit in many applications and introducing unnecessary information could increase the amount of training data required to achieve good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e90e7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY) # Converting from BGR to GRAYSCALE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea88f8",
   "metadata": {},
   "source": [
    "###### The below cell of code is to detect the face area from the image, it work as follow : \n",
    "* MultiScale detects objects of different sizes in the input image and returns rectangles positioned on the faces.\n",
    "* The first argument is the image, the second is the scalefactor, and the third is the minNeighbors.\n",
    "* The values of 1.3 and 5 are based on experimenting and choosing those that worked best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f2227af",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray,1.3,5) # Using for face area detection, as we discussed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe84334",
   "metadata": {},
   "source": [
    "###### The below cell of code is to iterate through the features of the faces and using our model to predict the output. Few important lines of the code written below are explained as : \n",
    "* ```for (x,y,w,h) in faces```, We will loop through rectangle (each face detected) using its coordinates generated by the function we discussed above.\n",
    "* ```img = gray[y-50:y+40+h,x-10:x+10+w]```, here we are setting img to our region of interest.\n",
    "* ```cv2.rectangle(pic,(x,y),(x+w,y+h),(0,225,0),4)```,  here we are drawing the rectangle in the original image. The (255,0,0) is the color of the frame in RGB. The last parameter (4) is the thickness of the rectangle. x is the horizontal initial position, w is the width, y is the vertical initial position, h is the height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9ce49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = [] # Creating empty list, age.\n",
    "gender = [] # Creating empty list gender.\n",
    "for (x,y,w,h) in faces:\n",
    "  img = gray[y-50:y+40+h,x-10:x+10+w] \n",
    "  img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) # Converting our image from GRAY to RGB, as we have extracted the features.\n",
    "  img = cv2.resize(img,(200,200)) # Resizing the original image to 200 X 200.\n",
    "  predict = model.predict(np.array(img).reshape(-1,200,200,3)) # Predicting from our imported model, after changing the image into an array and reshaping it.\n",
    "  age.append(predict[0]) # Appending predicted age from predict variable in age list.\n",
    "  gender.append(np.argmax(predict[1])) # Appending the maximum, that is the value with more weight in gender list from the predicted values.\n",
    "  gend = np.argmax(predict[1]) # Keeping the gender value in seperate variable to change the categorical value into string.\n",
    "  if gend == 0:\n",
    "    gend = 'Man'\n",
    "    col = (255,0,0)\n",
    "  else:\n",
    "    gend = 'Female'\n",
    "    col = (203,12,255)\n",
    "  cv2.rectangle(pic,(x,y),(x+w,y+h),(0,225,0),4)\n",
    "  cv2.putText(pic,\"Age : \"+str(int(predict[0]))+\" / \"+str(gend),(x,y),cv2.FONT_HERSHEY_SIMPLEX,w*0.005,col,4) # Writing the predicted values on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9034f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"predicted2.jpg\",pic) # Saving the image to our output path by the name we provided below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
